{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d822b61c-c798-4930-b53f-f74123767ef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-24 22:23:46.011903: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-24 22:23:46.029495: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-24 22:23:46.029527: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-24 22:23:46.040101: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-24 22:23:47.179200: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    interpreter = tf.lite.Interpreter(model_path=\"ted_tflite_models/ted_model.tflite\")\n",
    "    interpreter.allocate_tensors()\n",
    "    print(\"Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ae3e4c-b11e-44cc-a7e4-d99f985f63b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor found: {'name': 'ted/up_conv_block_2/sequential_2/conv2d_transpose_2/BiasAdd;ted/up_conv_block_2/sequential_2/conv2d_transpose_2/conv2d_transpose;ted/up_conv_block_2/sequential_2/conv2d_transpose_2/BiasAdd/ReadVariableOp', 'index': 53, 'shape': array([  1, 176, 176,  16], dtype=int32), 'shape_signature': array([  1, 176, 176,  16], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n"
     ]
    }
   ],
   "source": [
    "# Получаем информацию о всех тензорах\n",
    "tensor_details = interpreter.get_tensor_details()\n",
    "\n",
    "# Поиск и вывод информации о tensor#58\n",
    "tensor_index = 53  # Это индекс тензора, указанный в предупреждении\n",
    "\n",
    "for tensor in tensor_details:\n",
    "    if tensor['index'] == tensor_index:\n",
    "        print(f\"Tensor found: {tensor}\")\n",
    "        break\n",
    "else:\n",
    "    print(f\"Tensor with index {tensor_index} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b94820ea-460c-44ee-b717-f856723acb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-24 22:24:02.712953: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-24 22:24:03.042975: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-24 22:24:03.043429: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-24 22:24:03.045394: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-24 22:24:03.045819: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-24 22:24:03.046190: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-24 22:24:03.104802: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-24 22:24:03.105007: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-24 22:24:03.105140: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-24 22:24:03.125250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 428 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpstciv092/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpstciv092/assets\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1724527446.749908   12233 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1724527446.749965   12233 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n",
      "2024-08-24 22:24:06.751286: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpstciv092\n",
      "2024-08-24 22:24:06.771984: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-08-24 22:24:06.772021: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpstciv092\n",
      "2024-08-24 22:24:06.833077: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-08-24 22:24:06.839673: I tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\n",
      "2024-08-24 22:24:07.091293: I tensorflow/cc/saved_model/loader.cc:218] Running initialization op on SavedModel bundle at path: /tmp/tmpstciv092\n",
      "2024-08-24 22:24:07.139786: I tensorflow/cc/saved_model/loader.cc:317] SavedModel load for tags { serve }; Status: success: OK. Took 388506 microseconds.\n",
      "2024-08-24 22:24:07.713289: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-24 22:24:08.386047: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3064] Estimated count of arithmetic ops: 1.799 G  ops, equivalently 0.899 G  MACs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "246164"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "model = tf.keras.layers.TFSMLayer('best_model', call_endpoint='serving_default')\n",
    "\n",
    "fixed_input = tf.keras.Input(shape=(352, 352, 3), batch_size=1)\n",
    "\n",
    "fixed_model = tf.keras.Model(inputs=fixed_input, outputs=model(fixed_input))\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(fixed_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"ted_tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "tflite_model_file = tflite_models_dir/\"ted_model.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5a9f290-f52c-4f21-93b4-03c2c0332275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx.utils.extract_model(\"teed_model.onnx\", \"teed_model_subgraph2_extracted.onnx\", [\"input\"] , [\"output2\"], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa304f34-f83d-4121-93b6-77294c9df8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "\n",
    "sess_options = rt.SessionOptions()\n",
    "\n",
    "# Set graph optimization level\n",
    "sess_options.graph_optimization_level = rt.GraphOptimizationLevel.ORT_ENABLE_EXTENDED\n",
    "\n",
    "# To enable model serialization after graph optimization set this\n",
    "sess_options.optimized_model_filepath = \"optimized_subgraph2.onnx\"\n",
    "\n",
    "session = rt.InferenceSession(\"teed_model_subgraph2_extracted.onnx\", sess_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb2fbc49-3a11-4b4d-8984-308137d166fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import numpy as np\n",
    "from onnx import numpy_helper\n",
    "from sklearn.cluster import KMeans\n",
    "from onnx import helper\n",
    "\n",
    "# Загрузка модели\n",
    "model_path = \"optimized_subgraph2.onnx\"\n",
    "model = onnx.load(model_path)\n",
    "\n",
    "\n",
    "\n",
    "# Извлечение весов из модели\n",
    "weights = []\n",
    "weight_names = []\n",
    "for initializer in model.graph.initializer:\n",
    "    tensor = numpy_helper.to_array(initializer)\n",
    "    if tensor.ndim > 1:  # Кластеризация применима к многомерным весам\n",
    "        weights.append(tensor)\n",
    "        weight_names.append(initializer.name)\n",
    "\n",
    "# Выполнение кластеризации весов\n",
    "max_clusters = 16  # Максимальное количество кластеров\n",
    "clustered_weights = []\n",
    "\n",
    "for w in weights:\n",
    "    original_shape = w.shape\n",
    "    w_flattened = w.flatten().reshape(-1, 1)\n",
    "    \n",
    "    # Определяем количество кластеров как минимум между max_clusters и уникальными значениями в весах\n",
    "    n_clusters = min(max_clusters, len(np.unique(w_flattened)))\n",
    "\n",
    "    # Выполнение KMeans кластеризации\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(w_flattened)\n",
    "    \n",
    "    # Замена весов на ближайшие центроиды\n",
    "    new_weights = kmeans.cluster_centers_[kmeans.labels_]\n",
    "    clustered_weights.append(new_weights.reshape(original_shape))\n",
    "\n",
    "# Замена весов в модели\n",
    "new_initializers = []\n",
    "for i, initializer in enumerate(model.graph.initializer):\n",
    "    if initializer.name in weight_names:\n",
    "        new_tensor = clustered_weights.pop(0)\n",
    "        new_initializer = numpy_helper.from_array(new_tensor, initializer.name)\n",
    "        new_initializers.append(new_initializer)\n",
    "    else:\n",
    "        new_initializers.append(initializer)\n",
    "\n",
    "# Очистка текущего списка инициализаторов и добавление новых\n",
    "del model.graph.initializer[:]\n",
    "model.graph.initializer.extend(new_initializers)\n",
    "\n",
    "# Сохранение обновленной модели\n",
    "onnx.save(model, \"model_clustered2.onnx\")\n",
    "\n",
    "# Тестирование модели с onnxruntime (опционально)\n",
    "import onnxruntime as ort\n",
    "\n",
    "session = ort.InferenceSession(\"model_clustered2.onnx\")\n",
    "# Загрузите входные данные и выполните инференс\n",
    "# input_name = session.get_inputs()[0].name\n",
    "# output_name = session.get_outputs()[0].name\n",
    "# result = session.run([output_name], {input_name: input_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f32c8310-39c7-4b76-b0f2-3a1eb0ee00ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile saved to onnxruntime_profile__2024-08-27_17-01-05.json\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Загрузка изображения\n",
    "image_path = \"PIXECT-20240826122749.jpg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Определение преобразований\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((352, 352)),  # Изменение размера изображения до 352x352\n",
    "    transforms.ToTensor(),  # Преобразование в тензор\n",
    "    transforms.Normalize(mean=[104.007, 116.669, 122.679], std=[0.229, 0.224, 0.225])  # Нормализация\n",
    "])\n",
    "\n",
    "# Применение преобразований к изображению\n",
    "image_tensor = transform(image)\n",
    "\n",
    "# Добавление измерения batch_size (например, batch_size=1)\n",
    "image_tensor = image_tensor.unsqueeze(0)\n",
    "\n",
    "# Преобразование тензора в numpy для подачи в ONNX Runtime\n",
    "image_numpy = image_tensor.numpy()\n",
    "\n",
    "# Загрузка модели ONNX с профилированием\n",
    "model_path = \"model_clustered.onnx\"\n",
    "sess_options = ort.SessionOptions()\n",
    "sess_options.enable_profiling = True  # Включение профилирования\n",
    "session = ort.InferenceSession(model_path, sess_options)\n",
    "\n",
    "# Получение имени входного и выходного тензоров\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "# Выполнение инференса с профилированием\n",
    "output = session.run([output_name], {input_name: image_numpy})\n",
    "\n",
    "# Завершение профилирования и получение пути к профилю\n",
    "profile_file = session.end_profiling()\n",
    "print(f\"Profile saved to {profile_file}\")\n",
    "\n",
    "# Дополнительно: можно проанализировать профиль, загрузив его в инструменты визуализации, такие как Chrome Tracing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ff988f-fee5-43d2-af19-570a6cba3d53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
